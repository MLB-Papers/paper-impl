{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35efed82-7bed-4a60-b1e0-4b7e7b669df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13240c15-d3f3-4bdc-9561-f5dff8b08884",
   "metadata": {},
   "source": [
    "# RNN Encoder-Decoder with GRU (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc629df1-fe0d-4c8c-b692-bfb45df7f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Update Gate, Reset Gate, Hidden State\n",
    "        self.W_z = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.W_r = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.W_h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        # Concatenate input and previous hidden state\n",
    "        combined = torch.cat([x, h_prev], dim=1)\n",
    "\n",
    "        # Update Gate 계산\n",
    "        z_t = torch.sigmoid(self.W_z(combined))\n",
    "\n",
    "        # Reset Gate 계산\n",
    "        r_t = torch.sigmoid(self.W_r(combined))\n",
    "\n",
    "        # reset된 h_prev와 input을 이용해 h_tilde 계산\n",
    "        combined_reset = torch.cat([x, r_t * h_prev], dim=1)\n",
    "        h_tilde = torch.tanh(self.W_h(combined_reset))\n",
    "\n",
    "        # 최종 hidden state 계산\n",
    "        h_t = (1 - z_t) * h_prev + z_t * h_tilde\n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "664c0b27-9db7-4de2-8f9c-3500c7225302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers=1, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.gru = GRUCell(emb_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        # src: (batch_size, src_len)\n",
    "        embedded = self.dropout(self.embedding(src))  # (batch_size, src_len, emb_dim)\n",
    "        batch_size, src_len, _ = embedded.size()\n",
    "        hidden = torch.zeros(batch_size, self.gru.hidden_size).to(src.device)\n",
    "        \n",
    "        for t in range(src_len):\n",
    "            hidden = self.gru(embedded[:, t, :], hidden)\n",
    "        \n",
    "        return hidden  # (batch_size, hidden_dim)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.gru = GRUCell(emb_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        # input: (batch_size)\n",
    "        input = input.unsqueeze(1)  # (batch_size, 1)\n",
    "        embedded = self.dropout(self.embedding(input))  # (batch_size, 1, emb_dim)\n",
    "        embedded = embedded.squeeze(1)  # (batch_size, emb_dim)\n",
    "        \n",
    "        hidden = self.gru(embedded, hidden)  # (batch_size, hidden_dim)\n",
    "        output = self.fc_out(hidden)  # (batch_size, output_dim)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee990b7-98f2-4893-83df-9ed7b9f8dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.5):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        # src: (batch_size, src_len)\n",
    "        # trg: (batch_size, trg_len)\n",
    "        \n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        output_dim = self.decoder.fc_out.out_features\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "        \n",
    "        hidden = self.encoder(src)  # (batch_size, hidden_dim)\n",
    "        \n",
    "        # 첫 번째 디코더 입력은 <sos> 토큰\n",
    "        input = trg[:, 0]  # (batch_size)\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)  # output: (batch_size, output_dim)\n",
    "            outputs[:, t, :] = output\n",
    "            \n",
    "            teacher_force = torch.rand(1).item() < self.teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)  # (batch_size)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22798d7b-f8c9-4b98-9380-ce5bff537b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장 (예: batch_size=2, src_len=5)\n",
    "src = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 0, 0, 0]  # 두 번째 문장은 짧아서 패딩(0) 처리\n",
    "]).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 목표 문장 (예: batch_size=2, trg_len=6)\n",
    "trg = torch.tensor([\n",
    "    [1, 6, 7, 8, 9, 2],  # 1은 <sos>, 2는 <eos> 토큰을 의미\n",
    "    [1, 6, 7, 2, 0, 0]   # 패딩된 문장\n",
    "]).to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5b249f9-ce45-484b-963f-54a9ebed914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "INPUT_DIM = 10    # 입력 단어 집합 크기 (예: 10개 단어)\n",
    "OUTPUT_DIM = 10   # 출력 단어 집합 크기 (예: 10개 단어)\n",
    "EMB_DIM = 8       # 임베딩 차원 크기\n",
    "HIDDEN_DIM = 16   # 은닉 상태 크기\n",
    "DROPOUT = 0.1     # 드롭아웃 비율\n",
    "\n",
    "# GPU/CPU 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Encoder, Decoder, Seq2Seq 모델 초기화\n",
    "encoder = Encoder(INPUT_DIM, EMB_DIM, HIDDEN_DIM, dropout=DROPOUT).to(device)\n",
    "decoder = Decoder(OUTPUT_DIM, EMB_DIM, HIDDEN_DIM, dropout=DROPOUT).to(device)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5e3e1f-c841-460f-8688-ed681cb45db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 출력 (확률 분포):\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000],\n",
      "         [-0.0891,  0.2669, -0.2985,  0.1132, -0.2887,  0.0848, -0.0970,\n",
      "          -0.3222,  0.3882,  0.0369],\n",
      "         [-0.1549,  0.3043, -0.2245,  0.0191, -0.2597, -0.0256, -0.1229,\n",
      "          -0.2898,  0.2709,  0.0398],\n",
      "         [ 0.0161,  0.2831, -0.1423,  0.0825, -0.1603, -0.0221, -0.0956,\n",
      "          -0.2152,  0.1873,  0.0827],\n",
      "         [ 0.0819,  0.1447, -0.0613, -0.0765, -0.0176,  0.2205,  0.1917,\n",
      "          -0.1474,  0.0438,  0.0674],\n",
      "         [ 0.0399,  0.2139, -0.0889, -0.0297, -0.0090,  0.1188,  0.1485,\n",
      "          -0.1828,  0.1010,  0.1320]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0602,  0.2433, -0.2138,  0.1204, -0.2673,  0.2614, -0.0456,\n",
      "          -0.1169,  0.2233,  0.1826],\n",
      "         [-0.0713,  0.2868, -0.1873,  0.0269, -0.2374,  0.0684, -0.0952,\n",
      "          -0.1577,  0.1849,  0.1322],\n",
      "         [ 0.0622,  0.2714, -0.1218,  0.0946, -0.1421,  0.0234, -0.0894,\n",
      "          -0.1423,  0.1346,  0.1381],\n",
      "         [ 0.2361,  0.2279, -0.1394, -0.0384, -0.0907,  0.2495,  0.2195,\n",
      "          -0.2955,  0.1071,  0.1106],\n",
      "         [ 0.1117,  0.2682, -0.1183, -0.0076, -0.0568,  0.1278,  0.1517,\n",
      "          -0.2622,  0.1157,  0.1546]]], device='cuda:0')\n",
      "\n",
      "예측된 토큰:\n",
      "tensor([[0, 8, 1, 1, 5, 1],\n",
      "        [0, 5, 1, 1, 5, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 모델을 평가 모드로 설정 (테스트 시에는 dropout 비활성화)\n",
    "model.eval()\n",
    "\n",
    "# 모델 실행\n",
    "with torch.no_grad():\n",
    "    output = model(src, trg)  # output: (batch_size, trg_len, output_dim)\n",
    "\n",
    "# 출력 확인 (확률 분포 형태)\n",
    "print(\"모델 출력 (확률 분포):\")\n",
    "print(output)\n",
    "\n",
    "# 각 시점에서 가장 높은 확률을 가지는 단어 인덱스 출력\n",
    "predicted_tokens = output.argmax(2)  # (batch_size, trg_len)\n",
    "print(\"\\n예측된 토큰:\")\n",
    "print(predicted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be67fc-1514-4e21-a979-e132b27e3a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
