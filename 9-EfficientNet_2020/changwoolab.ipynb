{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6oce8ScjkcUo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "from math import ceil\n",
        "from functools import partial\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eMooZDMjkjp5"
      },
      "outputs": [],
      "source": [
        "class ConvBNReLU(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, groups=1):\n",
        "        super(ConvBNReLU, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride,\n",
        "                              kernel_size//2, groups=groups, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JHhX4AuYlE11"
      },
      "outputs": [],
      "source": [
        "class SqueezeExcitation(nn.Module):\n",
        "    def __init__(self, in_channels, squeeze_factor=4):\n",
        "        super(SqueezeExcitation, self).__init__()\n",
        "        squeeze_channels = in_channels // squeeze_factor\n",
        "        self.fc1 = nn.Conv2d(in_channels, squeeze_channels, 1)\n",
        "        self.fc2 = nn.Conv2d(squeeze_channels, in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        scale = F.adaptive_avg_pool2d(x, 1)\n",
        "        scale = F.relu(self.fc1(scale), inplace=True)\n",
        "        scale = torch.sigmoid(self.fc2(scale))\n",
        "        return x * scale\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "D3mUxmeCm6Eb"
      },
      "outputs": [],
      "source": [
        "class MBConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, expand_ratio, stride, kernel_size):\n",
        "        super(MBConvBlock, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        expand_channels = in_channels * expand_ratio\n",
        "        self.use_residual = (self.stride == 1 and in_channels == out_channels)\n",
        "\n",
        "        layers = []\n",
        "        if expand_ratio != 1:\n",
        "            layers.append(ConvBNReLU(in_channels, expand_channels, kernel_size=1))\n",
        "\n",
        "        layers.extend([\n",
        "            ConvBNReLU(expand_channels, expand_channels, kernel_size=kernel_size, stride=stride, groups=expand_channels),\n",
        "            SqueezeExcitation(expand_channels),\n",
        "            nn.Conv2d(expand_channels, out_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        ])\n",
        "\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_residual:\n",
        "            return x + self.block(x)\n",
        "        else:\n",
        "            return self.block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8b6DbejTlu3f"
      },
      "outputs": [],
      "source": [
        "class EfficientNet(nn.Module):\n",
        "    def __init__(self, width_mult=1.0, depth_mult=1.0, resolution_mult=1.0, num_classes=1000, dropout_rate=0.2):\n",
        "        super(EfficientNet, self).__init__()\n",
        "\n",
        "        def round_filters(filters, width_mult):\n",
        "            return int(filters * width_mult)\n",
        "\n",
        "        def round_repeats(repeats, depth_mult):\n",
        "            return int(ceil(repeats * depth_mult))\n",
        "\n",
        "        settings = [\n",
        "            # expand_ratio, channels, repeats, stride, kernel_size\n",
        "            [1, 16, 1, 1, 3],\n",
        "            [6, 24, 2, 2, 3],\n",
        "            [6, 40, 2, 2, 5],\n",
        "            [6, 80, 3, 2, 3],\n",
        "            [6, 112, 3, 1, 5],\n",
        "            [6, 192, 4, 2, 5],\n",
        "            [6, 320, 1, 1, 3],\n",
        "        ]\n",
        "\n",
        "        out_channels = round_filters(32, width_mult)\n",
        "        features = [ConvBNReLU(3, out_channels, kernel_size=3, stride=2)]\n",
        "\n",
        "        in_channels = out_channels\n",
        "        for expand_ratio, channels, repeats, stride, kernel_size in settings:\n",
        "            out_channels = round_filters(channels, width_mult)\n",
        "            repeats = round_repeats(repeats, depth_mult)\n",
        "\n",
        "            for i in range(repeats):\n",
        "                stride = stride if i == 0 else 1\n",
        "                features.append(MBConvBlock(in_channels, out_channels, expand_ratio, stride, kernel_size))\n",
        "                in_channels = out_channels\n",
        "\n",
        "        out_channels = round_filters(1280, width_mult)\n",
        "        features.append(ConvBNReLU(in_channels, out_channels, kernel_size=1))\n",
        "\n",
        "        self.features = nn.Sequential(*features)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(out_channels, num_classes)\n",
        "\n",
        "        # Apply resolution scaling\n",
        "        self.resolution_mult = resolution_mult\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Scale the resolution before applying the features\n",
        "        if self.resolution_mult != 1.0:\n",
        "            new_size = [int(s * self.resolution_mult) for s in x.shape[2:]]\n",
        "            x = F.interpolate(x, size=new_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sCA7bJzzmyAP"
      },
      "outputs": [],
      "source": [
        "def efficientnet_b0(num_classes=1000):\n",
        "    return EfficientNet(width_mult=1.0, depth_mult=1.0, resolution_mult=1.0, num_classes=num_classes)\n",
        "\n",
        "def efficientnet_b1(num_classes=1000):\n",
        "    return EfficientNet(width_mult=1.0, depth_mult=1.1, resolution_mult=1.15, num_classes=num_classes)\n",
        "\n",
        "def efficientnet_b2(num_classes=1000):\n",
        "    return EfficientNet(width_mult=1.1, depth_mult=1.2, resolution_mult=1.2, num_classes=num_classes)\n",
        "\n",
        "def efficientnet_b3(num_classes=1000):\n",
        "    return EfficientNet(width_mult=1.2, depth_mult=1.4, resolution_mult=1.3, num_classes=num_classes)\n",
        "\n",
        "def efficientnet_b4(num_classes=1000):\n",
        "    return EfficientNet(width_mult=1.4, depth_mult=1.8, resolution_mult=1.4, num_classes=num_classes)\n",
        "\n",
        "def efficientnet_b5(num_classes=1000):\n",
        "    return EfficientNet(width_mult=1.6, depth_mult=2.2, resolution_mult=1.6, num_classes=num_classes)\n",
        "\n",
        "def efficientnet_b6(num_classes=1000):\n",
        "    return EfficientNet(width_mult=1.8, depth_mult=2.6, resolution_mult=1.8, num_classes=num_classes)\n",
        "\n",
        "def efficientnet_b7(num_classes=1000):\n",
        "    return EfficientNet(width_mult=2.0, depth_mult=3.1, resolution_mult=2.0, num_classes=num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "C2k7GbwHpg7w"
      },
      "outputs": [],
      "source": [
        "# Time to start train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "DlKAiSPguQLI"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_efficientnet(variant='b0', num_epochs=10, batch_size=64, learning_rate=0.001):\n",
        "    # Mapping of variant to model function\n",
        "    variant_map = {\n",
        "        'b0': efficientnet_b0,\n",
        "        'b1': efficientnet_b1,\n",
        "        'b2': efficientnet_b2,\n",
        "        'b3': efficientnet_b3,\n",
        "        'b4': efficientnet_b4,\n",
        "        'b5': efficientnet_b5,\n",
        "        'b6': efficientnet_b6,\n",
        "        'b7': efficientnet_b7\n",
        "    }\n",
        "\n",
        "    if variant not in variant_map:\n",
        "        raise ValueError(f\"Variant {variant} is not valid. Choose from 'b0' to 'b7'.\")\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((224, 224)),  # Resize to match EfficientNet input size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize to match EfficientNet input size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Initialize the model, loss function, and optimizer\n",
        "    model = variant_map[variant](num_classes=10)  # CIFAR-10 has 10 classes\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:    # Print every 100 mini-batches\n",
        "                print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f}%')\n",
        "\n",
        "    return model, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb_AsTAwu_dh",
        "outputId": "5d4b233f-3597-407c-d849-3b1924615e19"
      },
      "outputs": [],
      "source": [
        "# Perform training\n",
        "for variant in ['b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7']:\n",
        "    print(f\"Testing EfficientNet-{variant.upper()}\")\n",
        "    model, accuracy = train_and_evaluate_efficientnet(variant=variant)\n",
        "    print(f\"Model EfficientNet-{variant.upper()} achieved an accuracy of {accuracy:.2f}% on CIFAR-10\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbtljZFIvCdf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
